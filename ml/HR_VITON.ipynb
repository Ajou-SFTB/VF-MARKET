{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajou-SFTB/VF-MARKET/blob/main/ml/HR_VITON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQz8GvJwXdII"
      },
      "source": [
        "## 1. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNjaqpR5YeMx"
      },
      "source": [
        "### Openpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt-Wd5yCrCUw"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/bioroid17/HR-VITON-forked.git HR-VITON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oJW9UhVhaRC"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/CIHP_PGN.zip /content/\n",
        "# !cp /content/drive/MyDrive/detectron2.zip /content/\n",
        "# CIHP_PGN\n",
        "!gdown https://drive.google.com/uc?id=1ZNfYG4AchmAhwN7f856s97v5V6vv-V_I\n",
        "# detectron2\n",
        "!gdown https://drive.google.com/uc?id=1olLrYa8x3HpEYp8Us5mPPaSNV6eJJdGN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYps6NPHhWHJ"
      },
      "outputs": [],
      "source": [
        "!unzip CIHP_PGN.zip\n",
        "!unzip detectron2.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ue9HdsBmXins"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CMU-Perceptual-Computing-Lab/openpose.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  # see: https://github.com/CMU-Perceptual-Computing-Lab/openpose/issues/949\n",
        "  # install new CMake becaue of CUDA10\n",
        "  !wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz\n",
        "  !tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local\n",
        "  # clone openpose\n",
        "  !git clone -q --depth 1 $git_repo_url\n",
        "  !sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
        "  # install system dependencies\n",
        "  !apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev\n",
        "  # install python dependencies\n",
        "  !pip install -q youtube-dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYVYr_aG0jmF"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/openpose-models.zip /content\n",
        "!gdown https://drive.google.com/uc?id=1SN1d31LQPV45FScXzQL423UQR4-zO7k6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D3zPzQx1GVN"
      },
      "outputs": [],
      "source": [
        "!unzip /content/openpose-models.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SI52z--f1SHy"
      },
      "outputs": [],
      "source": [
        "!mv /content/models/pose/body_25/pose_iter_584000.caffemodel  /content/openpose/models/pose/body_25/pose_iter_584000.caffemodel\n",
        "!mv /content/models/pose/coco/pose_iter_440000.caffemodel  /content/openpose/models/pose/coco/pose_iter_440000.caffemodel\n",
        "!mv /content/models/pose/mpi/pose_iter_160000.caffemodel  /content/openpose/models/pose/mpi/pose_iter_160000.caffemodel\n",
        "!mv /content/models/face/pose_iter_116000.caffemodel  /content/openpose/models/face/pose_iter_116000.caffemodel\n",
        "!mv /content/models/hand/pose_iter_102000.caffemodel  /content/openpose/models/hand/pose_iter_102000.caffemodel\n",
        "!mv /content/models/hand/pose_iter_120000.caffemodel  /content/openpose/models/hand/pose_iter_120000.caffemodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuyiIZ-lPVvE"
      },
      "outputs": [],
      "source": [
        "# build openpose\n",
        "!cd openpose && rm -rf build || true && mkdir build && cd build && cmake .. && make -j`nproc`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4i1t_DtyXiVE"
      },
      "outputs": [],
      "source": [
        "!mkdir HR-VITON/data\n",
        "!mkdir HR-VITON/data/test\n",
        "\n",
        "# for storing input image\n",
        "!mkdir HR-VITON/data/test/image\n",
        "\n",
        "# # copy official provided data to image_path, you may need to download and unzip it in advance\n",
        "# !cp ./test/image/000* ./image_path/\n",
        "\n",
        "# create directories for generated results of OpenPose\n",
        "!mkdir HR-VITON/data/test/openpose_json\n",
        "!mkdir HR-VITON/data/test/openpose_img\n",
        "\n",
        "!mkdir HR-VITON/data/test/cloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-9CK9XBc0h1"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/human.jpg /content/HR-VITON/data/test/image\n",
        "!mv /content/HR-VITON/data/test/image/human.jpg /content/HR-VITON/data/test/image/00000.jpg\n",
        "!cp /content/drive/MyDrive/shirt.jpg /content/HR-VITON/data/test/cloth\n",
        "!mv /content/HR-VITON/data/test/cloth/shirt.jpg /content/HR-VITON/data/test/cloth/00000.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wxYfVKCAX6Is"
      },
      "outputs": [],
      "source": [
        "# # go to openpose directory\n",
        "# %cd openpose\n",
        "# # run openpose.bin\n",
        "# !./build/examples/openpose/openpose.bin --image_dir ../HR-VITON/data/test/image --disable_blending --display 0 --write_json ../HR-VITON/data/test/openpose_json --write_images ../HR-VITON/data/test/openpose_img --num_gpu 1 --num_gpu_start 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzrZrXbFYk7z"
      },
      "source": [
        "### Human parse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1sGJKCKfX71g"
      },
      "outputs": [],
      "source": [
        "# %%bash\n",
        "# FILE_NAME='./CIHP_pgn.zip'\n",
        "# FILE_ID='1Mqpse5Gen4V4403wFEpv3w3JAsWw2uhk'\n",
        "\n",
        "# curl -sc /tmp/cookie \"https://drive.google.com/uc?export=download&id=$FILE_ID\" > /dev/null\n",
        "# CODE=\"$(awk '/_warning_/ {print $NF}' /tmp/cookie)\"\n",
        "# curl -Lb /tmp/cookie \"https://drive.google.com/uc?export=download&confirm=${CODE}&id=$FILE_ID\" -o $FILE_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QH33gL6TX7zQ"
      },
      "outputs": [],
      "source": [
        "# !unzip CIHP_pgn.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7jSZkCqlX7xC"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/Engineering-Course/CIHP_PGN.git\n",
        "# %cd CIHP_PGN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sjj4uq00X7ul"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p ./checkpoint\n",
        "# !mkdir -p ./datasets/images\n",
        "# # You also need to download dataset provided or use your own images\n",
        "# !mv ../CIHP_pgn ./checkpoint/CIHP_pgn\n",
        "# !cp ../test/image/000* ./datasets/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S34JtZSRnht8",
        "outputId": "68239878-4dd6-4ec7-a882-4d54f9610b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,967 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.1 [339 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.4 [1,305 kB]\n",
            "Fetched 1,677 kB in 1s (1,988 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 121677 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.1\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 3.4.11.39\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.2.0.32 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.2.0.32\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (5.5.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (23.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel) (4.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel) (1.16.0)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install python3-pip\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install matplotlib opencv-python==4.2.0.32 Pillow scipy tensorflow==1.15\n",
        "!pip install ipykernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bH3LhtWpuXPW"
      },
      "outputs": [],
      "source": [
        "# !tf_upgrade_v2 --intree . --outtree . --copyotherfiles False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "T8pe9iMRh_SZ"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/HR-VITON/data/test/image-parse-v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Pn-yYchTsYs5"
      },
      "outputs": [],
      "source": [
        "# %cd CIHP_PGN\n",
        "# !python ./inf_pgn.py --directory ../HR-VITON/data/test/image --output ../human_parse_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YmYl2olmiUuS"
      },
      "outputs": [],
      "source": [
        "# !cp /content/human_parse_output/cihp_parsing_maps/* /content/HR-VITON/data/test/image-parse-v3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBS7moiAYnvm"
      },
      "source": [
        "### Densepose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfh0X6saZLne"
      },
      "outputs": [],
      "source": [
        "!python -m pip install -e detectron2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-4VaG99ZLk7"
      },
      "outputs": [],
      "source": [
        "%cd detectron2/projects/DensePose\n",
        "!pip install av>=8.0.3 opencv-python-headless>=4.5.3.56 scipy>=1.5.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OkdDTKocZLfF"
      },
      "outputs": [],
      "source": [
        "# For getting same input as HR-VITON, change ./densepose/vis/densepose_results.py in line 320\n",
        "# alpha=0.7 to 1\n",
        "# inplace=True to False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sJ1hSI20ZLZ9"
      },
      "outputs": [],
      "source": [
        "# change ./densepose/vis/base.py, line 38\n",
        "# image_target_bgr = image_bgr * 0\n",
        "# to\n",
        "# image_target_bgr = image_bgr\n",
        "# image_target_bgr *= 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "avRhr20DZLS3"
      },
      "outputs": [],
      "source": [
        "# To save file with name kept and in directory, change apply_net.py, line 286 and 287 to below\n",
        "\n",
        "# out_fname = './image-densepose/' + image_fpath.split('/')[-1]\n",
        "# out_dir = './image-densepose'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YVMQ87t1aGEd"
      },
      "outputs": [],
      "source": [
        "# !python apply_net.py show configs/densepose_rcnn_R_50_FPN_s1x.yaml \\\n",
        "# https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl \\\n",
        "# /content/HR-VITON/data/test/image dp_segm -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBdWOggEDuHJ",
        "outputId": "7b931a89-4552-4a0b-a818-c9679bd48d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pz-g0Nc5u4Qu"
      },
      "outputs": [],
      "source": [
        "# !mv /content/image-densepose /content/HR-VITON/data/test/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg-mOvveYnoM"
      },
      "source": [
        "### Cloth mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YXXlbDtaTNP"
      },
      "outputs": [],
      "source": [
        "!pip install carvekit_colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FkXat2TaT6K"
      },
      "outputs": [],
      "source": [
        "from carvekit.ml.files.models_loc import download_all\n",
        "download_all();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "x8jkX663aT38"
      },
      "outputs": [],
      "source": [
        "# !mkdir ./cloth\n",
        "# !cp ./test/cloth/000* ./cloth/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zV6-cP5vaT1a"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/HR-VITON/data/test/cloth-mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VbljawV6aTyo"
      },
      "outputs": [],
      "source": [
        "# #title Upload images from your computer\n",
        "# #markdown Description of parameters\n",
        "# #markdown - `SHOW_FULLSIZE`  - Shows image in full size (may take a long time to load)\n",
        "# #markdown - `PREPROCESSING_METHOD`  - Preprocessing method\n",
        "# #markdown - `SEGMENTATION_NETWORK`  - Segmentation network. Use `u2net` for hairs-like objects and `tracer_b7` for objects\n",
        "# #markdown - `POSTPROCESSING_METHOD`  - Postprocessing method\n",
        "# #markdown - `SEGMENTATION_MASK_SIZE` - Segmentation mask size. Use 640 for Tracer B7 and 320 for U2Net\n",
        "# #markdown - `TRIMAP_DILATION`  - The size of the offset radius from the object mask in pixels when forming an unknown area\n",
        "# #markdown - `TRIMAP_EROSION`  - The number of iterations of erosion that the object's mask will be subjected to before forming an unknown area\n",
        "\n",
        "# import os\n",
        "# import numpy as np\n",
        "# from PIL import Image, ImageOps\n",
        "# from carvekit.web.schemas.config import MLConfig\n",
        "# from carvekit.web.utils.init_utils import init_interface\n",
        "\n",
        "# SHOW_FULLSIZE = False #param {type:\"boolean\"}\n",
        "# PREPROCESSING_METHOD = \"none\" #param [\"stub\", \"none\"]\n",
        "# SEGMENTATION_NETWORK = \"tracer_b7\" #param [\"u2net\", \"deeplabv3\", \"basnet\", \"tracer_b7\"]\n",
        "# POSTPROCESSING_METHOD = \"fba\" #param [\"fba\", \"none\"]\n",
        "# SEGMENTATION_MASK_SIZE = 640 #param [\"640\", \"320\"] {type:\"raw\", allow-input: true}\n",
        "# TRIMAP_DILATION = 30 #param {type:\"integer\"}\n",
        "# TRIMAP_EROSION = 5 #param {type:\"integer\"}\n",
        "# DEVICE = 'cuda' # 'cuda', 'cpu'\n",
        "\n",
        "# config = MLConfig(segmentation_network=SEGMENTATION_NETWORK,\n",
        "#                   preprocessing_method=PREPROCESSING_METHOD,\n",
        "#                   postprocessing_method=POSTPROCESSING_METHOD,\n",
        "#                   seg_mask_size=SEGMENTATION_MASK_SIZE,\n",
        "#                   trimap_dilation=TRIMAP_DILATION,\n",
        "#                   trimap_erosion=TRIMAP_EROSION,\n",
        "#                   device=DEVICE)\n",
        "\n",
        "# interface = init_interface(config)\n",
        "\n",
        "# imgs = []\n",
        "# root = './HR-VITON/data/test/cloth'\n",
        "# for name in os.listdir(root):\n",
        "#     imgs.append(root + '/' + name)\n",
        "\n",
        "# images = interface(imgs)\n",
        "# for i, im in enumerate(images):\n",
        "#     img = np.array(im)\n",
        "#     img = img[...,:3] # no transparency\n",
        "#     idx = (img[...,0]==130)&(img[...,1]==130)&(img[...,2]==130) # background 0 or 130, just try it\n",
        "#     img = np.ones(idx.shape)*255\n",
        "#     img[idx] = 0\n",
        "#     im = Image.fromarray(np.uint8(img), 'L')\n",
        "#     im.save(f'./HR-VITON/data/test/cloth-mask/{imgs[i].split(\"/\")[-1].split(\".\")[0]}.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJNBuWPMYmom"
      },
      "source": [
        "### Parse agnostic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "z3078zmSaTwP"
      },
      "outputs": [],
      "source": [
        "# Here is the parse label and corresponding body parts. You may need or not.\n",
        "# 0 - 20\n",
        "# Background\n",
        "# Hat\n",
        "# Hair\n",
        "# Glove\n",
        "# Sunglasses\n",
        "# Upper-clothes\n",
        "# Dress\n",
        "# Coat\n",
        "# Socks\n",
        "# Pants\n",
        "# tosor-skin\n",
        "# Scarf\n",
        "# Skirt\n",
        "# Face\n",
        "# Left-arm\n",
        "# Right-arm\n",
        "# Left-leg\n",
        "# Right-leg\n",
        "# Left-shoe\n",
        "# Right-shoe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "PZVUI3E3bDSx"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from os import path as osp\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_im_parse_agnostic(im_parse, pose_data, w=768, h=1024):\n",
        "    label_array = np.array(im_parse)\n",
        "    parse_upper = ((label_array == 5).astype(np.float32) +\n",
        "                    (label_array == 6).astype(np.float32) +\n",
        "                    (label_array == 7).astype(np.float32))\n",
        "    parse_neck = (label_array == 10).astype(np.float32)\n",
        "\n",
        "    r = 10\n",
        "    agnostic = im_parse.copy()\n",
        "\n",
        "    # mask arms\n",
        "    for parse_id, pose_ids in [(14, [2, 5, 6, 7]), (15, [5, 2, 3, 4])]:\n",
        "        mask_arm = Image.new('L', (w, h), 'black')\n",
        "        mask_arm_draw = ImageDraw.Draw(mask_arm)\n",
        "        i_prev = pose_ids[0]\n",
        "        for i in pose_ids[1:]:\n",
        "            if (pose_data[i_prev, 0] == 0.0 and pose_data[i_prev, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n",
        "                continue\n",
        "            mask_arm_draw.line([tuple(pose_data[j]) for j in [i_prev, i]], 'white', width=r*10)\n",
        "            pointx, pointy = pose_data[i]\n",
        "            radius = r*4 if i == pose_ids[-1] else r*15\n",
        "            mask_arm_draw.ellipse((pointx-radius, pointy-radius, pointx+radius, pointy+radius), 'white', 'white')\n",
        "            i_prev = i\n",
        "        parse_arm = (np.array(mask_arm) / 255) * (label_array == parse_id).astype(np.float32)\n",
        "        agnostic.paste(0, None, Image.fromarray(np.uint8(parse_arm * 255), 'L'))\n",
        "\n",
        "    # mask torso & neck\n",
        "    agnostic.paste(0, None, Image.fromarray(np.uint8(parse_upper * 255), 'L'))\n",
        "    agnostic.paste(0, None, Image.fromarray(np.uint8(parse_neck * 255), 'L'))\n",
        "\n",
        "    return agnostic\n",
        "\n",
        "\n",
        "# if __name__ ==\"__main__\":\n",
        "#     data_path = './HR-VITON/data/test/'\n",
        "#     output_path = './HR-VITON/data/test/image-parse-agnostic-v3.2'\n",
        "\n",
        "#     os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "#     for im_name in tqdm(os.listdir(osp.join(data_path, 'image'))):\n",
        "\n",
        "#         # load pose image\n",
        "#         pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
        "\n",
        "#         try:\n",
        "#             with open(osp.join(data_path, 'openpose_json', pose_name), 'r') as f:\n",
        "#                 pose_label = json.load(f)\n",
        "#                 pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
        "#                 pose_data = np.array(pose_data)\n",
        "#                 pose_data = pose_data.reshape((-1, 3))[:, :2]\n",
        "#         except IndexError:\n",
        "#             print(pose_name)\n",
        "#             continue\n",
        "\n",
        "#         # load parsing image\n",
        "#         parse_name = im_name.replace('.jpg', '.png')\n",
        "#         im_parse = Image.open(osp.join(data_path, 'image-parse-v3', parse_name))\n",
        "\n",
        "#         agnostic = get_im_parse_agnostic(im_parse, pose_data)\n",
        "\n",
        "#         agnostic.save(osp.join(output_path, parse_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaKyrzO1Yy4j"
      },
      "source": [
        "### Human agnostic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "l0kfmchxbqAo"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from os import path as osp\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_img_agnostic(img, parse, pose_data):\n",
        "    parse_array = np.array(parse)\n",
        "    parse_head = ((parse_array == 4).astype(np.float32) +\n",
        "                    (parse_array == 13).astype(np.float32))\n",
        "    parse_lower = ((parse_array == 9).astype(np.float32) +\n",
        "                    (parse_array == 12).astype(np.float32) +\n",
        "                    (parse_array == 16).astype(np.float32) +\n",
        "                    (parse_array == 17).astype(np.float32) +\n",
        "                    (parse_array == 18).astype(np.float32) +\n",
        "                    (parse_array == 19).astype(np.float32))\n",
        "\n",
        "\n",
        "    agnostic = img.copy()\n",
        "    agnostic_draw = ImageDraw.Draw(agnostic)\n",
        "\n",
        "    length_a = np.linalg.norm(pose_data[5] - pose_data[2])\n",
        "    length_b = np.linalg.norm(pose_data[12] - pose_data[9])\n",
        "    point = (pose_data[9] + pose_data[12]) / 2\n",
        "    pose_data[9] = point + (pose_data[9] - point) / length_b * length_a\n",
        "    pose_data[12] = point + (pose_data[12] - point) / length_b * length_a\n",
        "    r = int(length_a / 16) + 1\n",
        "\n",
        "    # mask arms\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 5]], 'gray', width=r*10)\n",
        "    for i in [2, 5]:\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n",
        "    for i in [3, 4, 6, 7]:\n",
        "        if (pose_data[i - 1, 0] == 0.0 and pose_data[i - 1, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n",
        "            continue\n",
        "        agnostic_draw.line([tuple(pose_data[j]) for j in [i - 1, i]], 'gray', width=r*10)\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n",
        "\n",
        "    # mask torso\n",
        "    for i in [9, 12]:\n",
        "        pointx, pointy = pose_data[i]\n",
        "        agnostic_draw.ellipse((pointx-r*3, pointy-r*6, pointx+r*3, pointy+r*6), 'gray', 'gray')\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 9]], 'gray', width=r*6)\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [5, 12]], 'gray', width=r*6)\n",
        "    agnostic_draw.line([tuple(pose_data[i]) for i in [9, 12]], 'gray', width=r*12)\n",
        "    agnostic_draw.polygon([tuple(pose_data[i]) for i in [2, 5, 12, 9]], 'gray', 'gray')\n",
        "\n",
        "    # mask neck\n",
        "    pointx, pointy = pose_data[1]\n",
        "    agnostic_draw.rectangle((pointx-r*7, pointy-r*7, pointx+r*7, pointy+r*7), 'gray', 'gray')\n",
        "    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_head * 255), 'L'))\n",
        "    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_lower * 255), 'L'))\n",
        "\n",
        "    return agnostic\n",
        "\n",
        "# if __name__ ==\"__main__\":\n",
        "#     data_path = './HR-VITON/data/test/'\n",
        "#     output_path = './HR-VITON/data/test/agnostic-v3.2'\n",
        "\n",
        "#     os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "#     for im_name in tqdm(os.listdir(osp.join(data_path, 'image'))):\n",
        "\n",
        "#         # load pose image\n",
        "#         pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
        "\n",
        "#         try:\n",
        "#             with open(osp.join(data_path, 'openpose_json', pose_name), 'r') as f:\n",
        "#                 pose_label = json.load(f)\n",
        "#                 pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
        "#                 pose_data = np.array(pose_data)\n",
        "#                 pose_data = pose_data.reshape((-1, 3))[:, :2]\n",
        "#         except IndexError:\n",
        "#             print(pose_name)\n",
        "#             continue\n",
        "\n",
        "#         # load parsing image\n",
        "#         im = Image.open(osp.join(data_path, 'image', im_name))\n",
        "#         label_name = im_name.replace('.jpg', '.png')\n",
        "#         im_label = Image.open(osp.join(data_path, 'image-parse-v3', label_name))\n",
        "\n",
        "#         agnostic = get_img_agnostic(im, im_label, pose_data)\n",
        "\n",
        "#         agnostic.save(osp.join(output_path, im_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZhQAz9hXUKD"
      },
      "source": [
        "## 2. Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYDnPusKwsQs",
        "outputId": "8b1329ef-16d7-4a5c-8576-96b6c0950bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HR-VITON\n"
          ]
        }
      ],
      "source": [
        "%cd HR-VITON/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XWJq6ew6Su6"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch-lts -c nvidia\n",
        "!pip install opencv-python torchgeometry Pillow tqdm tensorboardX scikit-image scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG7W02aeDFlp",
        "outputId": "b4c286df-e05d-4d9a-dd6f-998965d9d956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HR-VITON\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5jtpmloQj0k"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/Colab\\ Notebooks/hr-viton-weights.zip /content\n",
        "# hr-viton-weights.zip\n",
        "!gdown https://drive.google.com/uc?id=1ypB6mNJZSc5varNrXAMOrlTvvXXSMWjk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcLpDL7pwrJo"
      },
      "outputs": [],
      "source": [
        "!unzip ./hr-viton-weights.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "uTFGM11xgTG4"
      },
      "outputs": [],
      "source": [
        "!rm /content/HR-VITON/hr-viton-weights.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "OIzwM1opSapc"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"/content/HR-VITON/data\"):\n",
        "  os.mkdir(\"/content/HR-VITON/data\")\n",
        "if not os.path.exists(\"/content/HR-VITON/eval_models/weights\"):\n",
        "  os.mkdir(\"/content/HR-VITON/eval_models/weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "cgyPk5AM39s0"
      },
      "outputs": [],
      "source": [
        "!mv /content/HR-VITON/v0.1 /content/HR-VITON/eval_models/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "3-IwrDGSoGOP"
      },
      "outputs": [],
      "source": [
        "# !python3 train_generator.py --cuda True --name test -b 4 -j 8 --gpu_ids 0 --tocg_checkpoint ./checkpoints/tocg_final.pth --occlusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrpvjmTT10Aj"
      },
      "outputs": [],
      "source": [
        "!pip install flask\n",
        "!pip install flask-restx\n",
        "!pip install pyngrok\n",
        "!pip install flask-ngrok\n",
        "!pip install flask_cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rtoN9_7ypuw",
        "outputId": "0fe53b94-8878-48d4-834c-644d24e7df35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "lldCg7FxU_kJ"
      },
      "outputs": [],
      "source": [
        "!mkdir static/\n",
        "!mkdir static/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VNqS9mUs2nv"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "ngrokauthtoken = userdata.get('ngrokauthtoken')\n",
        "!ngrok authtoken $ngrokauthtoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph-0vq7ns9pa"
      },
      "outputs": [],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz\n",
        "!tar -xvf /content/ngrok-stable-linux-amd64.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWMaTrC1_M5P"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "# Open a TCP ngrok tunnel to the SSH server\n",
        "connection_string = ngrok.connect(\"22\", \"tcp\").public_url\n",
        "\n",
        "ssh_url, port = connection_string.strip(\"tcp://\").split(\":\")\n",
        "print(f\" * ngrok tunnel available, access with `ssh root@{ssh_url} -p{port}`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "bXm6nL3Ba8VD"
      },
      "outputs": [],
      "source": [
        "# !mkdir ~/.config/ngrok\n",
        "# !mv ~/.ngrok2/ngrok.yml ~/.config/ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "3G0U7zXZVV7e"
      },
      "outputs": [],
      "source": [
        "# !ssh root@2.tcp.ngrok.io -p16483"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "vEcRqJoDO5xn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps\n",
        "from carvekit.web.schemas.config import MLConfig\n",
        "from carvekit.web.utils.init_utils import init_interface\n",
        "\n",
        "def run_openpose(dirname):\n",
        "  os.system(f\"mkdir static/{dirname}/test/openpose_img\")\n",
        "  os.system(f\"mkdir static/{dirname}/test/openpose_json\")\n",
        "  os.chdir(\"openpose\")\n",
        "  os.system(f\"./build/examples/openpose/openpose.bin --image_dir ../static/{dirname}/test/image --disable_blending \\\n",
        "  --display 0 --write_json ../static/{dirname}/test/openpose_json --write_images ../static/{dirname}/test/openpose_img \\\n",
        "  --num_gpu 1 --num_gpu_start 0\")\n",
        "  os.chdir(\"..\")\n",
        "\n",
        "def run_human_parse(dirname):\n",
        "  os.system(f\"mkdir static/{dirname}/test/image-parse-v3\")\n",
        "  os.chdir(\"CIHP_PGN\")\n",
        "  os.system(f\"python ./inf_pgn.py --directory ../static/{dirname}/test/image --output ../human_parse_output\")\n",
        "  os.chdir(\"..\")\n",
        "  os.system(f\"cp /content/human_parse_output/cihp_parsing_maps/* /content/static/{dirname}/test/image-parse-v3\")\n",
        "\n",
        "def run_densepose(dirname):\n",
        "  os.chdir(\"detectron2/projects/DensePose\")\n",
        "  os.system(f\"python apply_net.py show configs/densepose_rcnn_R_50_FPN_s1x.yaml \\\n",
        "  https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl \\\n",
        "  /content/static/{dirname}/test/image dp_segm -v\")\n",
        "  os.chdir(\"../../..\")\n",
        "  os.system(f\"mv /content/image-densepose /content/static/{dirname}/test/\")\n",
        "\n",
        "def run_cloth_mask(dirname):\n",
        "  os.system(f\"mkdir static/{dirname}/test/cloth-mask\")\n",
        "  SHOW_FULLSIZE = False #param {type:\"boolean\"}\n",
        "  PREPROCESSING_METHOD = \"none\" #param [\"stub\", \"none\"]\n",
        "  SEGMENTATION_NETWORK = \"tracer_b7\" #param [\"u2net\", \"deeplabv3\", \"basnet\", \"tracer_b7\"]\n",
        "  POSTPROCESSING_METHOD = \"fba\" #param [\"fba\", \"none\"]\n",
        "  SEGMENTATION_MASK_SIZE = 640 #param [\"640\", \"320\"] {type:\"raw\", allow-input: true}\n",
        "  TRIMAP_DILATION = 30 #param {type:\"integer\"}\n",
        "  TRIMAP_EROSION = 5 #param {type:\"integer\"}\n",
        "  DEVICE = 'cuda' # 'cuda', 'cpu'\n",
        "\n",
        "  config = MLConfig(segmentation_network=SEGMENTATION_NETWORK,\n",
        "                    preprocessing_method=PREPROCESSING_METHOD,\n",
        "                    postprocessing_method=POSTPROCESSING_METHOD,\n",
        "                    seg_mask_size=SEGMENTATION_MASK_SIZE,\n",
        "                    trimap_dilation=TRIMAP_DILATION,\n",
        "                    trimap_erosion=TRIMAP_EROSION,\n",
        "                    device=DEVICE)\n",
        "\n",
        "  interface = init_interface(config)\n",
        "\n",
        "  imgs = []\n",
        "  root = f'./static/{dirname}/test/cloth'\n",
        "  for name in os.listdir(root):\n",
        "    imgs.append(root + '/' + name)\n",
        "\n",
        "  images = interface(imgs)\n",
        "  for i, im in enumerate(images):\n",
        "    img = np.array(im)\n",
        "    img = img[...,:3] # no transparency\n",
        "    idx = (img[...,0]==130)&(img[...,1]==130)&(img[...,2]==130) # background 0 or 130, just try it\n",
        "    img = np.ones(idx.shape)*255\n",
        "    img[idx] = 0\n",
        "    im = Image.fromarray(np.uint8(img), 'L')\n",
        "    im.save(f'./static/{dirname}/test/cloth-mask/{imgs[i].split(\"/\")[-1].split(\".\")[0]}.jpg')\n",
        "\n",
        "def run_parse_agnostic(dirname):\n",
        "    data_path = f'./static/{dirname}/test/'\n",
        "    output_path = f'./static/{dirname}/test/image-parse-agnostic-v3.2'\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    for im_name in tqdm(os.listdir(osp.join(data_path, 'image'))):\n",
        "\n",
        "        # load pose image\n",
        "        pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
        "\n",
        "        try:\n",
        "            with open(osp.join(data_path, 'openpose_json', pose_name), 'r') as f:\n",
        "                pose_label = json.load(f)\n",
        "                pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
        "                pose_data = np.array(pose_data)\n",
        "                pose_data = pose_data.reshape((-1, 3))[:, :2]\n",
        "        except IndexError:\n",
        "            print(pose_name)\n",
        "            continue\n",
        "\n",
        "        # load parsing image\n",
        "        parse_name = im_name.replace('.jpg', '.png')\n",
        "        im_parse = Image.open(osp.join(data_path, 'image-parse-v3', parse_name))\n",
        "\n",
        "        agnostic = get_im_parse_agnostic(im_parse, pose_data)\n",
        "\n",
        "        agnostic.save(osp.join(output_path, parse_name))\n",
        "\n",
        "def run_human_agnostic(dirname):\n",
        "    data_path = f'./static/{dirname}/test/'\n",
        "    output_path = f'./static/{dirname}/test/agnostic-v3.2'\n",
        "\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    for im_name in tqdm(os.listdir(osp.join(data_path, 'image'))):\n",
        "\n",
        "        # load pose image\n",
        "        pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
        "\n",
        "        try:\n",
        "            with open(osp.join(data_path, 'openpose_json', pose_name), 'r') as f:\n",
        "                pose_label = json.load(f)\n",
        "                pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
        "                pose_data = np.array(pose_data)\n",
        "                pose_data = pose_data.reshape((-1, 3))[:, :2]\n",
        "        except IndexError:\n",
        "            print(pose_name)\n",
        "            continue\n",
        "\n",
        "        # load parsing image\n",
        "        im = Image.open(osp.join(data_path, 'image', im_name))\n",
        "        label_name = im_name.replace('.jpg', '.png')\n",
        "        im_label = Image.open(osp.join(data_path, 'image-parse-v3', label_name))\n",
        "\n",
        "        agnostic = get_img_agnostic(im, im_label, pose_data)\n",
        "\n",
        "        agnostic.save(osp.join(output_path, im_name))\n",
        "\n",
        "def run_inference(dirname):\n",
        "  os.chdir(\"HR-VITON\")\n",
        "  os.system(f\"python3 test_generator.py --occlusion --cuda True --test_name inference \\\n",
        "   --tocg_checkpoint ./eval_models/weights/v0.1/mtviton.pth --gpu_ids 0 --gen_checkpoint ./eval_models/weights/v0.1/gen.pth \\\n",
        "   --datasetting unpaired --dataroot ../static/{dirname}/ --data_list test_pairs.txt --output_dir ../static/{dirname}/output\")\n",
        "  os.chdir(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIFGIA_Pj2iu"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify, send_file\n",
        "from flask_cors import CORS\n",
        "from werkzeug.utils import secure_filename\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from pyngrok import ngrok\n",
        "import uuid\n",
        "\n",
        "app = Flask(\"VirtualFitting\")\n",
        "port = \"5000\"\n",
        "app.config['JSONIFY_PRETTYPRINT_REGULAR'] = False\n",
        "# run_with_ngrok(app)  # Start ngrok when app is run\n",
        "\n",
        "# Open a ngrok tunnel to the HTTP server\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n",
        "\n",
        "# Update any base URLs to use the public ngrok URL\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "\n",
        "CORS(app,  supports_credentials=True)\n",
        "\n",
        "@app.route(\"/getprod\", methods=[\"POST\"])\n",
        "def getprod():\n",
        "  cloth = request.files['product']\n",
        "  clothname = secure_filename(cloth.filename)\n",
        "  prod_id = str(request.form['prodId'])\n",
        "  user_id = str(request.form['userId'])\n",
        "  dirname = prod_id + \"_\" + user_id\n",
        "  filename = dirname + \".jpg\"\n",
        "\n",
        "  os.system(f\"mkdir ./static/{dirname}\")\n",
        "  os.system(f\"mkdir ./static/{dirname}/test\")\n",
        "  os.system(f\"mkdir ./static/{dirname}/test/cloth\")\n",
        "  os.system(f\"mkdir ./static/{dirname}/test/image\")\n",
        "\n",
        "  clothpath = f\"./static/{dirname}/test/cloth/{filename}\"\n",
        "\n",
        "  cloth.save(clothpath)\n",
        "  resize_cloth = Image.open(clothpath)\n",
        "  resize_cloth.resize((768, 1024)).save(clothpath)\n",
        "\n",
        "  return jsonify({\n",
        "      \"dirname\": dirname,\n",
        "      \"clothsrc\": f\"{request.host_url}static/{dirname}/test/cloth/{filename}\",\n",
        "      \"hostUrl\": request.host_url\n",
        "  })\n",
        "\n",
        "@app.route(\"/showimage\", methods=[\"POST\"])\n",
        "def showimage():  # GET 요청시 리턴 값에 해당 하는 dict를 JSON 형태로 반환\n",
        "  image = request.files['image']\n",
        "  dirname = request.form['dirname']\n",
        "  filename = dirname + \".jpg\"\n",
        "\n",
        "  imagepath = f\"./static/{dirname}/test/image/{filename}\"\n",
        "\n",
        "  image.save(imagepath)\n",
        "\n",
        "  resize_image = Image.open(imagepath)\n",
        "  resize_image.resize((768, 1024)).save(imagepath)\n",
        "  resize_image.resize((768, 1024)).save(imagepath)\n",
        "\n",
        "  os.system(f\"touch ./static/{dirname}/test_pairs.txt\")\n",
        "  textfile = open(f\"./static/{dirname}/test_pairs.txt\", 'w')\n",
        "  data = f\"{dirname}.jpg {dirname}.jpg\\n\"\n",
        "  textfile.write(data)\n",
        "  textfile.close()\n",
        "\n",
        "  print(\"가상피팅 시작!\")\n",
        "  run_openpose(dirname)\n",
        "  run_human_parse(dirname)\n",
        "  run_densepose(dirname)\n",
        "  run_cloth_mask(dirname)\n",
        "  run_parse_agnostic(dirname)\n",
        "  run_human_agnostic(dirname)\n",
        "  run_inference(dirname)\n",
        "\n",
        "  result_name = dirname + \"_\" + dirname + \".png\"\n",
        "  os.system(f\"mv ./static/{dirname}/output/{result_name} ./static/{dirname}/output/{dirname}.png\")\n",
        "  print(\"가상피팅 완료!\")\n",
        "  return jsonify({\n",
        "      \"resultSrc\": f\"{request.host_url}static/{dirname}/output/{dirname}.png\"\n",
        "  })\n",
        "\n",
        "@app.route(\"/export\", methods=[\"POST\"])\n",
        "def export():\n",
        "  dirname = request.form[\"dirname\"]\n",
        "  filepath = f\"./static/{dirname}/output/{dirname}.png\"\n",
        "\n",
        "  return send_file(filepath, mimetype=\"image/png\")\n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "  return \"Hello, from colab\"\n",
        "\n",
        "app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "AVOyfwfcJxB3"
      },
      "outputs": [],
      "source": [
        "ngrok.disconnect(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "DiiNCHDC9nGi"
      },
      "outputs": [],
      "source": [
        "# !dpkg -s libc6 | grep Arch"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOimXPAGaW1Y/3u7cwKUj89",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}